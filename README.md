# ğŸ©º Heart Disease Prediction using Decision Trees and Random Forests

## ğŸ“Œ Task 5 - AI & ML Internship

This project is part of an AI & ML internship focused on learning tree-based models for classification using the Heart Disease Dataset from Kaggle.

ğŸ”— **Dataset Used:**  
[Heart Disease Dataset - Kaggle](https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset)

---

## ğŸ›  Tools & Libraries
- Python
- Scikit-learn
- Pandas & NumPy
- Matplotlib & Seaborn
- Graphviz

---

## ğŸ“ Files in This Repo

- `heart_disease_analysis.ipynb`: Jupyter notebook with all code and analysis.
- `heart.csv`: Dataset (extracted from `.zip`).
- `tree.dot` (optional): DOT file for decision tree visualization using Graphviz.
- `README.md`: Project documentation.

---

## âœ… Objectives

- Train and visualize a **Decision Tree Classifier**
- Control overfitting using **max_depth**
- Train and evaluate a **Random Forest Classifier**
- Compare accuracy of models
- Analyze **feature importance**
- Use **cross-validation** for model evaluation

---

## ğŸ§ª Steps Performed

1. Loaded and explored the dataset.
2. Split data into training and test sets.
3. Trained a Decision Tree Classifier.
4. Visualized the decision tree using `plot_tree` and optionally `graphviz`.
5. Controlled tree overfitting by limiting max depth.
6. Trained a Random Forest Classifier.
7. Compared accuracy of both models.
8. Plotted and interpreted feature importances.
9. Performed k-fold cross-validation.

---

## ğŸ“Š Model Performance

| Model               | Accuracy |
|---------------------|----------|
| Decision Tree       | XX.XX %  |
| Decision Tree (Limited Depth) | XX.XX %  |
| Random Forest       | XX.XX %  |
| Random Forest (CV Avg) | XX.XX % |

_(Replace with your actual results)_

---

## ğŸ“ˆ Visuals

- Decision Tree Diagram
- Feature Importance Bar Chart
- Confusion Matrix Heatmap

---

## ğŸ§  Key Learnings

- Decision trees are simple yet powerful models.
- Random forests reduce overfitting via ensemble learning (bagging).
- Feature importance can help understand model decision-making.
- Cross-validation gives more reliable performance metrics.

---

## ğŸ“¤ Submission

Submitted via [Google Form](https://forms.gle/8Gm83s53KbyXs3Ne9)

---

## ğŸ¤ Credits

Thanks to the internship organizers and Kaggle dataset contributors.

---

